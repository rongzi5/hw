{
 "cells": [
  {
   "cell_type": "code",
   "id": "8f4f0d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:30:22.724311Z",
     "start_time": "2024-09-10T10:30:11.614664Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Normalize(mean = [0.5],std = [0.5])])\n",
    "\n",
    "path = './data/' \n",
    "trainData = torchvision.datasets.MNIST(path,train = True,transform = transform,download = True)\n",
    "testData = torchvision.datasets.MNIST(path,train = False,transform = transform)\n",
    "\n",
    "BATCH_SIZE = 256  \n",
    "trainDataLoader = torch.utils.data.DataLoader(dataset = trainData,batch_size = BATCH_SIZE,shuffle = True)\n",
    "testDataLoader = torch.utils.data.DataLoader(dataset = testData,batch_size = BATCH_SIZE)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 1,out_channels = 16,kernel_size = 3,stride = 1,padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = 16,out_channels = 32,kernel_size = 3,stride = 1,padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = 32,out_channels = 64,kernel_size = 3,stride = 1,padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features = 7 * 7 * 64,out_features = 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features = 128,out_features = 10),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.model(input)\n",
    "        return output\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5e589d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:33:14.877270Z",
     "start_time": "2024-09-10T10:30:24.898741Z"
    }
   },
   "source": [
    "net = Net().to(device)\n",
    "lossF = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(1,EPOCHS + 1):\n",
    "    processBar = tqdm(trainDataLoader,unit = 'step')\n",
    "    net.train(True)\n",
    "    for step,(trainImgs,labels) in enumerate(processBar):\n",
    "        trainImgs = trainImgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        net.zero_grad()\n",
    "        outputs = net(trainImgs)\n",
    "        loss = lossF(outputs,labels)\n",
    "        predictions = torch.argmax(outputs, dim = 1)\n",
    "        accuracy = torch.sum(predictions == labels)/labels.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        processBar.set_description(\"[%d/%d] Loss: %.4f, Acc: %.4f\" % \n",
    "                                    (epoch,EPOCHS,loss.item(),accuracy.item()))\n",
    "        \n",
    "torch.save(net.state_dict(), 'model.pth')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/10] Loss: 1.7162, Acc: 0.7396: 100%|██████████| 235/235 [00:18<00:00, 13.02step/s]\n",
      "[2/10] Loss: 1.5094, Acc: 0.9479: 100%|██████████| 235/235 [00:16<00:00, 14.41step/s]\n",
      "[3/10] Loss: 1.4741, Acc: 0.9896: 100%|██████████| 235/235 [00:16<00:00, 13.98step/s]\n",
      "[4/10] Loss: 1.4842, Acc: 0.9792: 100%|██████████| 235/235 [00:16<00:00, 13.95step/s]\n",
      "[5/10] Loss: 1.4618, Acc: 1.0000: 100%|██████████| 235/235 [00:16<00:00, 14.26step/s]\n",
      "[6/10] Loss: 1.4849, Acc: 0.9792: 100%|██████████| 235/235 [00:16<00:00, 14.26step/s]\n",
      "[7/10] Loss: 1.4653, Acc: 1.0000: 100%|██████████| 235/235 [00:16<00:00, 14.06step/s]\n",
      "[8/10] Loss: 1.4614, Acc: 1.0000: 100%|██████████| 235/235 [00:17<00:00, 13.82step/s]\n",
      "[9/10] Loss: 1.4842, Acc: 0.9792: 100%|██████████| 235/235 [00:16<00:00, 14.46step/s]\n",
      "[10/10] Loss: 1.4842, Acc: 0.9792: 100%|██████████| 235/235 [00:18<00:00, 12.97step/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "625da4fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:34:14.610975Z",
     "start_time": "2024-09-10T10:34:03.171403Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = Net()\n",
    "model_path = 'model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "cap = cv2.VideoCapture('tem.mp4')\n",
    "track_id = 0\n",
    "tracks = {}\n",
    "output_video_path = 'output_video.mp4'\n",
    "np.random.seed(0)\n",
    "colors = [(0,0,0),(0,0,255),(0,255,0),(255,0,0),(255,255,0),(255,0,255),(0,255,255),(255,255,255),(50,150,200),(200,150,50)]\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def detect_digits(frame, tracks, track_id):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    w0,h0=gray.shape\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    contours, tem1= cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    out=torch.randn(1,1,28,28)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w<30 and h<30:\n",
    "             continue\n",
    "        tem=gray[max(0,y-10):min(w0,y+h+10),max(0,x-10):max(h0,x+w+10)]\n",
    "        tem=cv2.resize(tem, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        tem=torch.from_numpy(tem)\n",
    "        tem=tem.view(1,1,28,28)\n",
    "        out=torch.cat((out,tem),dim=0)\n",
    "        tracks[track_id] = {'x': x, 'y': y, 'w': w, 'h': h, 'contour': contour}\n",
    "        track_id += 1\n",
    "    out=out[1:,:,:,:]\n",
    "    num=model(out)\n",
    "    _, max_indices = torch.max(num, dim=1)\n",
    "    for i in range(len(max_indices)):\n",
    "        tracks[i].update({'num':max_indices[i].item()})\n",
    "\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fgMask = backSub.apply(frame)\n",
    "    detect_digits(frame, tracks, track_id)\n",
    "    for track_id, rect in tracks.items():\n",
    "        x, y, w, h,num = rect['x'], rect['y'], rect['w'], rect['h'],rect['num']\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colors[num], 2)\n",
    "        cv2.putText(frame, str(num), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, colors[num], 2)\n",
    "    track_id = 0\n",
    "    tracks = {}\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b0911d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:35:31.372553Z",
     "start_time": "2024-09-10T10:35:31.341519Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def gaussian2d_labels(sz,sigma):\n",
    "    w,h=sz\n",
    "    xs, ys = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    center_x, center_y = w / 2, h / 2\n",
    "    dist = ((xs - center_x) ** 2 + (ys - center_y) ** 2) / (sigma**2)\n",
    "    labels = np.exp(-0.5*dist)\n",
    "    return labels\n",
    "    \n",
    "def cos_window(sz):\n",
    "    \"\"\"\n",
    "    width, height = sz\n",
    "    j = np.arange(0, width)\n",
    "    i = np.arange(0, height)\n",
    "    J, I = np.meshgrid(j, i)\n",
    "    cos_window = np.sin(np.pi * J / width) * np.sin(np.pi * I / height)\n",
    "    \"\"\"\n",
    "    cos_window = np.hanning(int(sz[1]))[:, np.newaxis].dot(np.hanning(int(sz[0]))[np.newaxis, :])\n",
    "    return cos_window\n",
    "\n",
    "class BaseCF:\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def init(self,first_frame,bbox):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(self,current_frame):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class MOSSE(BaseCF):\n",
    "    def __init__(self,interp_factor=0.125,sigma=2.):\n",
    "        super(MOSSE).__init__()\n",
    "        self.interp_factor=interp_factor\n",
    "        self.sigma=sigma\n",
    "\n",
    "    def init(self,first_frame,bbox):\n",
    "        if len(first_frame.shape)!=2:\n",
    "            assert first_frame.shape[2]==3\n",
    "            first_frame=cv2.cvtColor(first_frame,cv2.COLOR_BGR2GRAY)\n",
    "        first_frame=first_frame.astype(np.float32)/255\n",
    "        x,y,w,h=tuple(bbox)\n",
    "        self._center=(x+w/2,y+h/2)\n",
    "        self.w,self.h=w,h\n",
    "        w,h=int(round(w)),int(round(h))\n",
    "        self.cos_window=cos_window((w,h))\n",
    "        self._fi=cv2.getRectSubPix(first_frame,(w,h),self._center)\n",
    "        self._G=np.fft.fft2(gaussian2d_labels((w,h),self.sigma))\n",
    "        self.crop_size=(w,h)\n",
    "        self._Ai=np.zeros_like(self._G)\n",
    "        self._Bi=np.zeros_like(self._G)\n",
    "        for _ in range(8):\n",
    "            fi=self._rand_warp(self._fi)\n",
    "            Fi=np.fft.fft2(self._preprocessing(fi,self.cos_window))\n",
    "            self._Ai+=self._G*np.conj(Fi)\n",
    "            self._Bi+=Fi*np.conj(Fi)\n",
    "\n",
    "\n",
    "    def update(self,current_frame,vis=False):\n",
    "        if len(current_frame.shape)!=2:\n",
    "            assert current_frame.shape[2]==3\n",
    "            current_frame=cv2.cvtColor(current_frame,cv2.COLOR_BGR2GRAY)\n",
    "        current_frame=current_frame.astype(np.float32)/255\n",
    "        Hi=self._Ai/self._Bi\n",
    "        fi=cv2.getRectSubPix(current_frame,(int(round(self.w)),int(round(self.h))),self._center)\n",
    "        fi=self._preprocessing(fi,self.cos_window)\n",
    "        Gi=Hi*np.fft.fft2(fi)\n",
    "        gi=np.real(np.fft.ifft2(Gi))\n",
    "        if vis is True:\n",
    "            self.score=gi\n",
    "        curr=np.unravel_index(np.argmax(gi, axis=None),gi.shape)\n",
    "        dy,dx=curr[0]-(self.h/2),curr[1]-(self.w/2)\n",
    "        x_c,y_c=self._center\n",
    "        x_c+=dx\n",
    "        y_c+=dy\n",
    "        self._center=(x_c,y_c)\n",
    "        fi=cv2.getRectSubPix(current_frame,(int(round(self.w)),int(round(self.h))),self._center)\n",
    "        fi=self._preprocessing(fi,self.cos_window)\n",
    "        Fi=np.fft.fft2(fi)\n",
    "        self._Ai=self.interp_factor*(self._G*np.conj(Fi))+(1-self.interp_factor)*self._Ai\n",
    "        self._Bi=self.interp_factor*(Fi*np.conj(Fi))+(1-self.interp_factor)*self._Bi\n",
    "        return [self._center[0]-self.w/2,self._center[1]-self.h/2,self.w,self.h]\n",
    "\n",
    "    def _preprocessing(self,img,cos_window,eps=1e-5):\n",
    "        img=np.log(img+1)\n",
    "        img=(img-np.mean(img))/(np.std(img)+eps)\n",
    "        return cos_window*img\n",
    "\n",
    "    def _rand_warp(self,img):\n",
    "        h, w = img.shape[:2]\n",
    "        C = .1\n",
    "        ang = np.random.uniform(-C, C)\n",
    "        c, s = np.cos(ang), np.sin(ang)\n",
    "        W = np.array([[c + np.random.uniform(-C, C), -s + np.random.uniform(-C, C), 0],\n",
    "                      [s + np.random.uniform(-C, C), c + np.random.uniform(-C, C), 0]])\n",
    "        center_warp = np.array([[w / 2], [h / 2]])\n",
    "        tmp = np.sum(W[:, :2], axis=1).reshape((2, 1))\n",
    "        W[:, 2:] = center_warp - center_warp * tmp\n",
    "        warped = cv2.warpAffine(img, W, (w, h), cv2.BORDER_REFLECT)\n",
    "        return warped\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "0908401d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:36:22.835903Z",
     "start_time": "2024-09-10T10:35:32.117256Z"
    }
   },
   "source": [
    "def track_and_save_video(video_path, output_path, initial_bbox):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame of the video.\")\n",
    "        return\n",
    "    tracker=[]\n",
    "    for i in initial_bbox:\n",
    "        tracker1 = MOSSE()\n",
    "        tracker1.init(frame, i)\n",
    "        tracker.append(tracker1)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        bbox=[]\n",
    "        for i in range(len(initial_bbox)):\n",
    "            bbox= tracker[i].update(frame)\n",
    "            x, y, w, h = bbox\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Tracking', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "video_path = 'pedestrians.avi'  \n",
    "output_path = 'catch.avi' \n",
    "def select_roi_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return None\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame of the video.\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    cap.release()\n",
    "    roi = cv2.selectROI(frame, showCrosshair=True, fromCenter=False)\n",
    "    x, y, w, h = roi\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.imshow('Selected ROI', frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    roi_image = frame[int(y):int(y+h), int(x):int(x+w)]\n",
    "    return roi_image,[x, y, w, h]\n",
    "\n",
    "n=int(input('选取数:'))\n",
    "roi_image=[]\n",
    "pos=[]\n",
    "for i in range(n):\n",
    "    roi_image1,pos1 = select_roi_from_video(video_path)\n",
    "    roi_image.append(roi_image1)\n",
    "    pos.append(pos1)\n",
    "\n",
    "    if roi_image is not None:\n",
    "        cv2.imshow('Cropped ROI', roi_image[-1])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "initial_bbox = pos  \n",
    "\n",
    "track_and_save_video(video_path, output_path, initial_bbox)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc529d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
