{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像透视变换\n",
    "- 输入图像，顺时针依次用鼠标点击四个点，作为仿射变换后和原图左上、右上、右下、左下四个点对应的点。\n",
    "- 按下Enter键，对图像做透视变换。\n",
    "- 将边界黑色背景区域设置为透明，保存新的图像。"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T12:32:35.375539Z",
     "start_time": "2024-09-02T12:32:29.415527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个全局变量来保存点击的点\n",
    "points = []\n",
    "\n",
    "# 鼠标回调函数，用于获取鼠标点击的坐标\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global points, img_copy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points.append((x, y))\n",
    "        # 更新显示的图像\n",
    "        img_copy = img.copy()\n",
    "        for point in points:\n",
    "            cv2.circle(img_copy, point, 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(\"image\", img_copy)\n",
    "\n",
    "# 读取输入图像\n",
    "img = cv2.imread('./input/test.png')\n",
    "img_copy = img.copy()\n",
    "\n",
    "# 显示图像并获取用户点击的四个点\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.setMouseCallback(\"image\", select_points)\n",
    "\n",
    "while True:\n",
    "    if len(points) == 4:\n",
    "        # 按下 Enter 键继续\n",
    "        if cv2.waitKey(1) & 0xFF == 13:\n",
    "            print(\"Performing perspective transformation...\")\n",
    "            break\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 定义目标矩形的大小、输出图像的位置\n",
    "width, height = 500, 500\n",
    "pts1 = np.float32(points)\n",
    "pts2 = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "# 计算透视变换矩阵\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "# 进行透视变换\n",
    "warped_img = cv2.warpPerspective(img, M, (width, height))\n",
    "\n",
    "# 将黑色背景区域设置为透明\n",
    "gray = cv2.cvtColor(warped_img, cv2.COLOR_BGR2GRAY)\n",
    "_, alpha = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)  # 使用阈值1来处理几乎黑色的区域\n",
    "b, g, r = cv2.split(warped_img)\n",
    "rgba = [b, g, r, alpha]\n",
    "warped_img_with_alpha = cv2.merge(rgba, 4)\n",
    "\n",
    "# 保存结果\n",
    "cv2.imwrite('./output/2_3/warped_img_with_alpha.png', warped_img_with_alpha)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Warped Image', warped_img_with_alpha)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing perspective transformation...\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在2D平面可视化人体骨架数据\n",
    "- 基于某一动作的3D坐标序列画出该动作在一个2D平面上的投影\n",
    "- 要求模拟相机成像过程，设定相机的内参和外参\n",
    "- 不同关节点采用不同颜色表示，关节点之间的连线用两个节点的中间颜色"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置模拟相机参数矩阵"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T12:32:59.953898Z",
     "start_time": "2024-09-02T12:32:59.942370Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 模拟相机的内参矩阵 (Intrinsic Parameters)\n",
    "focal_length = 800  # 焦距\n",
    "principal_point = (400, 300)  # 主点（成像平面中心）\n",
    "camera_matrix = np.array([[focal_length, 0, principal_point[0]],\n",
    "                          [0, focal_length, principal_point[1]],\n",
    "                          [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "# 模拟相机的外参矩阵 (Extrinsic Parameters)\n",
    "rotation_vector = np.array([0.0, 0.0, 0.0], dtype=np.float64)  # 无旋转\n",
    "translation_vector = np.array([0.0, 0.0, -1000.0], dtype=np.float64)  # 沿Z轴向后移1000单位"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载3D骨架数据，并建立骨架连接关系"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T12:33:00.720973Z",
     "start_time": "2024-09-02T12:33:00.697930Z"
    }
   },
   "source": [
    "\n",
    "# 加载3D骨架数据\n",
    "data = np.load('./input/brushing_hair.npy')\n",
    "\n",
    "# 骨架连接关系\n",
    "connections = [\n",
    "    (1, 2), (2, 21), (21, 3), (3, 4),  # 脊柱\n",
    "    (21, 5), (5, 6), (6, 7), (7, 8), (8, 23), (23, 22),  # 右臂\n",
    "    (21, 9), (9, 10), (10, 11), (11, 12), (12, 25), (25, 24),  # 左臂\n",
    "    (13, 14), (14, 15), (15, 16),  # 右腿\n",
    "    (17, 18), (18, 19), (19, 20),  # 左腿\n",
    "]\n",
    "\n",
    "# 选择要可视化的帧\n",
    "frame_index = 0  # 可视化第一个动作帧\n",
    "skeleton_3d = data[frame_index]\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加合适的缩放因子，使2D投影结果更加便于观察"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T12:33:01.513449Z",
     "start_time": "2024-09-02T12:33:01.500968Z"
    }
   },
   "source": [
    "\n",
    "# 选择一个合适的缩放因子\n",
    "scale_factor = 150\n",
    "\n",
    "# 对 3D 坐标进行缩放\n",
    "skeleton_3d_scaled = skeleton_3d * scale_factor\n",
    "\n",
    "# 将缩放后的 3D 点投影到 2D 平面\n",
    "# 将3D点投影到2D平面\n",
    "skeleton_2d, _ = cv2.projectPoints(skeleton_3d_scaled, rotation_vector, translation_vector, camera_matrix, distCoeffs=None)\n",
    "\n",
    "# 保留小数形式的坐标\n",
    "skeleton_2d = skeleton_2d.reshape(-1, 2)\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将关节设置为不同的颜色"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T12:33:03.798276Z",
     "start_time": "2024-09-02T12:33:02.289868Z"
    }
   },
   "source": [
    "\n",
    "# 创建空白图像（背景）\n",
    "image = np.ones((600, 800, 3), dtype=np.uint8) * 255  # 白色背景\n",
    "\n",
    "joint_colors = [tuple(map(int, np.random.randint(0, 255, 3))) for _ in range(len(skeleton_2d))]\n",
    "\n",
    "for i, point in enumerate(skeleton_2d):\n",
    "    cv2.circle(image, tuple(np.round(point).astype(int)), 8, joint_colors[i], -1)\n",
    "\n",
    "\n",
    "for connection in connections:\n",
    "    pt1 = np.round(skeleton_2d[connection[0] - 1]).astype(int)\n",
    "    pt2 = np.round(skeleton_2d[connection[1] - 1]).astype(int)\n",
    "\n",
    "    color1 = np.array(joint_colors[connection[0] - 1])\n",
    "    color2 = np.array(joint_colors[connection[1] - 1])\n",
    "    mid_color = tuple(map(int, ((color1 + color2) // 2)))\n",
    "\n",
    "    cv2.line(image, tuple(pt1), tuple(pt2), mid_color, 4)\n",
    "\n",
    "\n",
    "# 显示图像\n",
    "cv2.imshow('Skeleton Projection', image)\n",
    "cv2.imwrite('./output/2_3/skeleton_projection.png', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
